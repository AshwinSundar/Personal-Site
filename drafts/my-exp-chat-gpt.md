
When I first began using GPT-3, my intention was to test it's limits. To see what it was capable of understanding and what kinds of questions it could answer. Early on, I was very impressed and knew I should write an article about it. I thought of folding it into my daily workflow, primarily to substitute Google, Stack Overflow, and public technical documentation on programming. In 50-75% of cases, it provided accurate and helpful information that enabled me to solve a problem quickly. 

I envisioned an article where I merely described a few programming use cases, and how it shined or failed in each case. Little did I know that I would soon fall down an artificial intelligence (AI) rabbit hole. 

I had previously used TabNine, an AI "pair programmer" that can autocomplete lines and entire functions. I had heard of GitHub CoPilot, and was vaguely familiar with some controversy around it.

I was not prepared for the philosophical discussions around AI tools like these. 
